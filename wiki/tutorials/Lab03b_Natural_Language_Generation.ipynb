{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6e1f6b4-d475-40ec-91b3-3ecca04a5cc2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Natural Language Generation\n",
    "\n",
    "For standard language generation:\n",
    " - https://huggingface.co/blog/how-to-generate\n",
    "  - https://huggingface.co/blog/introducing-csearch\n",
    "\n",
    "For constraint language generation:\n",
    " - https://huggingface.co/blog/constrained-beam-search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b512113c-b58b-4b4d-ad59-c296429a2dcd",
   "metadata": {},
   "source": [
    "## Auto-regressive Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03c87a2d-c5f1-425c-8ca7-1a6901f40486",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cuda.is_available: \t True\n",
      "cuda.device_count: \t 1\n",
      "cuda.current_device: \t 0\n",
      "cuda.device: \t\t <torch.cuda.device object at 0x7f5c4f80f580>\n",
      "\n",
      "cuda.get_device_name: \t NVIDIA GeForce RTX 3050 Ti Laptop GPU\n",
      "total memory: \t\t 4294508544\n",
      "reserved memory:\t 0\n",
      "allocated memory:\t 0\n",
      "\n",
      "device name: \t\t cuda:0\n",
      "transformers: \t\t 4.29.2\n",
      "pytorch: \t\t 2.0.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import transformers\n",
    "from transformers import GenerationConfig, AutoTokenizer, AutoModel, utils, BartForConditionalGeneration \n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "utils.logging.set_verbosity_error()  # Remove line to see warnings\n",
    "\n",
    "def cuda_info():\n",
    "    print()\n",
    "    print(\"cuda.is_available: \\t\", torch.cuda.is_available())\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"cuda.device_count: \\t\", torch.cuda.device_count())\n",
    "        print(\"cuda.current_device: \\t\", torch.cuda.current_device())\n",
    "        print(\"cuda.device: \\t\\t\", torch.cuda.device(torch.cuda.current_device()))\n",
    "        print()\n",
    "        print(\"cuda.get_device_name: \\t\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "        print(\"total memory: \\t\\t\", torch.cuda.get_device_properties(0).total_memory)\n",
    "        print(\"reserved memory:\\t\", torch.cuda.memory_reserved(0))\n",
    "        print(\"allocated memory:\\t\", torch.cuda.memory_allocated(0))\n",
    "\n",
    "\n",
    "    device = \"cuda:\" + str(torch.cuda.current_device()) if torch.cuda.is_available() else \"cpu\"\n",
    "    print()\n",
    "    print(\"device name: \\t\\t\", device)\n",
    "    print(\"transformers: \\t\\t\", transformers.__version__)\n",
    "    print(\"pytorch: \\t\\t\", torch.__version__)\n",
    "    \n",
    "def decode_and_print(model, config, sentence):\n",
    "\n",
    "    encoded_input_ids_1 = tokenizer(sentence, return_tensors=\"pt\", add_special_tokens=False).input_ids.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        generation_output = model.generate(\n",
    "            input_ids = encoded_input_ids_1,\n",
    "            generation_config = generation_config,\n",
    "            return_dict_in_generate = True,\n",
    "            output_scores = True\n",
    "        )\n",
    "\n",
    "    for s in generation_output.sequences:\n",
    "        output = tokenizer.decode(s, skip_special_tokens=True)\n",
    "        print(output)\n",
    "        \n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "cuda_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5306af5-63ea-421c-aa60-5c0b65b649e8",
   "metadata": {},
   "source": [
    "# Decoder models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23969f1f-8cdb-428f-a59b-ce2bb60cf74a",
   "metadata": {},
   "source": [
    "## DialogGPT\n",
    "\n",
    "https://huggingface.co/microsoft/DialoGPT-large\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7e62477-fbcc-4ad2-8849-fc40851c5b84",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cuda.is_available: \t True\n",
      "cuda.device_count: \t 1\n",
      "cuda.current_device: \t 0\n",
      "cuda.device: \t\t <torch.cuda.device object at 0x7f2a5cbdde50>\n",
      "\n",
      "cuda.get_device_name: \t NVIDIA GeForce RTX 3050 Ti Laptop GPU\n",
      "total memory: \t\t 4294508544\n",
      "reserved memory:\t 3290431488\n",
      "allocated memory:\t 3210018816\n",
      "\n",
      "device name: \t\t cuda:0\n",
      "transformers: \t\t 4.29.2\n",
      "pytorch: \t\t 2.0.0\n"
     ]
    }
   ],
   "source": [
    "model_name = \"microsoft/DialoGPT-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "cuda_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd9001e4-8565-4142-b0c5-421e1dfa6a79",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> User: Good morning! How are you today?\n",
      "DialoGPT: Good morning! I'm doing well. How are you?\n",
      ">> User: Fine, but it's raining today.\n",
      "DialoGPT: I know that feel.\n",
      ">> User: How's the weather there?\n",
      "DialoGPT: Cloudy and raining.\n",
      ">> User: Don't you like rain?\n",
      "DialoGPT: I love rain.\n",
      ">> User: How many wives to I need?\n",
      "DialoGPT: I have no wives.\n"
     ]
    }
   ],
   "source": [
    "# Let's chat for 5 lines\n",
    "for step in range(5):\n",
    "    # encode the new user input, add the eos_token and return a tensor in Pytorch\n",
    "    new_user_input_ids = tokenizer.encode(input(\">> User:\") + tokenizer.eos_token, return_tensors='pt')\n",
    "\n",
    "    # append the new user input tokens to the chat history\n",
    "    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if step > 0 else new_user_input_ids\n",
    "\n",
    "    # generated a response while limiting the total chat history to 1000 tokens, \n",
    "    chat_history_ids = model.generate(bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "    # pretty print last ouput tokens from bot\n",
    "    print(\"DialoGPT: {}\".format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218ae51c-bf0e-492b-8a0d-845e6ea59b32",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## BART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e788c834-e350-433c-9ea6-bfaeda9f5705",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cuda.is_available: \t True\n",
      "cuda.device_count: \t 1\n",
      "cuda.current_device: \t 0\n",
      "cuda.device: \t\t <torch.cuda.device object at 0x7fab387cb8e0>\n",
      "\n",
      "cuda.get_device_name: \t NVIDIA GeForce RTX 3050 Ti Laptop GPU\n",
      "total memory: \t\t 4294508544\n",
      "reserved memory:\t 1635778560\n",
      "allocated memory:\t 1625362944\n",
      "\n",
      "device name: \t\t cuda:0\n",
      "transformers: \t\t 4.29.2\n",
      "pytorch: \t\t 2.0.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize tokenizer and model. Be sure to set output_attentions=True.\n",
    "# Load BART fine-tuned for summarization on CNN/Daily Mail dataset\n",
    "model_name = \"facebook/bart-large-cnn\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name, output_attentions=True).to(device)\n",
    "cuda_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20062e5b-d18c-472b-9b0b-f1db0c0bce27",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Decoding Strategies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5751a268-03f6-43d9-a83f-fd35867684f6",
   "metadata": {},
   "source": [
    "## Decoding parameters and example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a6d0c2b-8783-4b03-9d1b-e4bb4e9a7128",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"max_new_tokens\": 150,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"output_attentions\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"temperature\": 0.4,\n",
      "  \"top_k\": 10,\n",
      "  \"top_p\": 0.8,\n",
      "  \"transformers_version\": \"4.29.2\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generation_config = model.generation_config\n",
    "\n",
    "generation_config.temperature = 0.4\n",
    "generation_config.top_p = 0.8\n",
    "generation_config.top_k = 10\n",
    "generation_config.num_beams = 4\n",
    "generation_config.max_new_tokens = 150\n",
    "\n",
    "print(generation_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9186b97d-1366-4ad5-a033-e30d5aa75117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "House Budget Committee passes a spending bill. House Budget Committee passed a spending bills. House budget committee passed a bill to fund the government. The spending bill was passed by the House of Representatives. The Senate will vote on the spending bill later this month. The bill is expected to be approved by the Senate on Thursday.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# create ids of encoded input vectors\n",
    "sentence = 'The House Budget Committee passed a spending bill.'\n",
    "\n",
    "decode_and_print(model, generation_config, sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8f4020-83f4-4dd8-942f-5c3e0f739646",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Greedy Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cb5bfe5-7968-4356-9a8e-f57e468cd2dd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "generation_config = model.generation_config\n",
    "generation_config.do_sample = False\n",
    "generation_config.num_beams = 1\n",
    "generation_config.max_new_tokens = 150\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d72e195-676e-4b0d-ac19-58b3dcfdf19f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "House Budget Committee passed a spending bill. House Budget Committee passing a spendingBill. House budget Committee passed spending bill, passed bill. Bill passed by House Budget committee. House passed spending Bill. House passes spending bill; bill passed by Senate. House votes on bill. Senate votes on spending bill and passes bill.\n"
     ]
    }
   ],
   "source": [
    "sentence = 'The House Budget Committee passed a spending bill.'\n",
    "\n",
    "decode_and_print(model, generation_config, sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815a3d2b-5909-4165-8c7e-1aad48b906c9",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4da6886-b273-4695-bc86-c352c0553f3d",
   "metadata": {},
   "source": [
    "### Multinomial Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0a2d8e-e79a-4945-bc74-0402b5b0b862",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Top-k Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fada6ee-2e3d-49fd-add6-bc5f75e019f8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"do_sample\": true,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"max_new_tokens\": 150,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"output_attentions\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"top_k\": 10,\n",
      "  \"top_p\": 0.8,\n",
      "  \"transformers_version\": \"4.29.2\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = 'The House Budget Committee passed a spending bill.'\n",
    "\n",
    "generation_config = model.generation_config\n",
    "generation_config.do_sample = True\n",
    "generation_config.num_beams = 1\n",
    "generation_config.temperature = 1\n",
    "\n",
    "print(generation_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5022f514-7cd4-4a64-bd8d-3ad420947ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Top k  1\n",
      "House Budget Committee passed a spending bill. House Budget Committee pass a spending law. House will vote on the bill again next week. House budget committee passed bill with no amendments. House voted to pass bill with amendments. It would provide for a two-year, $3.8 billion spending program.\n",
      "\n",
      "## Top k  2\n",
      "House Budget Committee passed a spending bill. House Budget Committee passes a spending bills. House budget committee passed a bill to fund the government. House passed a spent bill. No amendments were passed. House will vote on the bill in September. House is scheduled to vote again in December.\n",
      "\n",
      "## Top k  3\n",
      "House Budget Committee passed a spending bill. House Budget Committee pass a spending passed a bill. Congress passes a spending. bill. It passed by House vote. The bill will be signed into law by President Barack Obama. The Senate will have to vote again on the bill.\n",
      "\n",
      "## Top k  4\n",
      "House Budget Committee passed a spending bill. House Budget Committee Passed a spending bills bill. passed a bill for the next year. House passed a spent bill. A bill passed in the Senate. House budget committee passed the bill. It passed a reading of the bill, the House budget bill.\n",
      "\n",
      "## Top k  5\n",
      "House Budget Committee passed a spending bill. House Budget CommitteePassed a spendingBill. House budget bill passed. House has passed spending bill with some changes. House to debate bill next week. Budget Committee votes to pass bill. Committee passed bill with amendments. House passes spending bill to stop federal spending.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in range(1,6):\n",
    "    \n",
    "    print(\"## Top k \", n*10)\n",
    "    generation_config.top_k = n*10\n",
    "    decode_and_print(model, generation_config, sentence)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc19464-b352-425f-aec6-058f2368ce14",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Top-p sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6339d304-f3f5-4030-a8c0-8d41ccefbb30",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"do_sample\": true,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"max_new_tokens\": 150,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"output_attentions\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"top_p\": 0.8,\n",
      "  \"transformers_version\": \"4.29.2\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = 'The House Budget Committee passed a spending bill.'\n",
    "\n",
    "generation_config = model.generation_config\n",
    "generation_config.do_sample = True\n",
    "generation_config.num_beams = 1\n",
    "generation_config.temperature = 1\n",
    "\n",
    "print(generation_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bbfdc15-58aa-4a98-b9f4-b35ded0673b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Top p  0.15000000000000002\n",
      "House Budget Committee passed a spending bill. House Budget Committee passing a spendingBill. House budget Committee passed spending bill for the year. House passed spending Bill. House passes spending bill, House passes bill. Senate passes spending Bill, House votes on bill. The bill is expected to be signed into law.\n",
      "\n",
      "## Top p  0.35000000000000003\n",
      "House Budget Committee passed a spending bill. House Budget Committee passing a spending Bill. House passed a bill to fund the government. House passes a spendingBill. House votes on the bill. The bill is sent to the House of Representatives. The House votes to pass the bill on a vote of approval.\n",
      "\n",
      "## Top p  0.55\n",
      "House Budget Committee passed a spending bill. House Budget Committee Passed a spendingBill. House has passed a bill to spend the money. House passed a measure to fund the government. House will now vote on the bill again. House also passed a separate bill to fund a program to help the military.\n",
      "\n",
      "## Top p  0.75\n",
      "House Budget Committee passed a spending bill. House Budget Committee passing a spending measure. House budget bill passed by House Budget committee. House will have to pass a spending plan before the end of the year. House passed a bill for the current spending bill on July 1.\n",
      "\n",
      "## Top p  0.95\n",
      "House Budget Committee passed a spending bill. House Budget Committee passes a spending report. House  votes on a spending plan and sends it to White House. There are some differences, but spending will be limited, House Republicans say. House Speaker Paul Ryan: Spending bill is a bill of rights for the American people.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in range(1,6):\n",
    "    generation_config.top_p = 0.2*n-0.05\n",
    "    print(\"## Top p \", generation_config.top_p)\n",
    "    decode_and_print(model, generation_config, sentence)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541d8d73-c519-4417-87ef-300f948224e9",
   "metadata": {},
   "source": [
    "### Contrastive Search\n",
    "https://huggingface.co/blog/introducing-csearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44ccef8-2f34-471a-9f60-890c72c1bc29",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97a6d9a9-e8e2-488d-b24c-3733b219c90c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: \n",
      "House Budget Committee passes a spending bill that would fund the national debt. House Committee passes the bill without incident. House Speaker John Boehner and the House Appropriations Committee take up a bill later this week. But the Senate version will soon pass after a vote from Speaker Boehner and a House vote by the Senate committee.\n",
      "\n",
      "Output: \n",
      "House Budget Committee passed a spending bill. House Budget Committee. passed a funding bill for education, energy, health and human services. House budget bill passed by committee. House vote set for next week. House passed Senate bill. Vote for House bill expected Tuesday. Republicans in House have proposed a bill that would fund the government through a compromise.\n",
      "\n",
      "Output: \n",
      "The House Budget Committee passed a spending bill. House Budget committee passed a  spending bill; the Senate voted on a new spending bill Saturday. House Speaker John Boehner said the spending bill's passage would allow him to balance the budget. The bill will cost $54.4 billion.\n",
      "\n",
      "Output: \n",
      "U.S. House Budget Committee passed a spending bill. House Appropriations Committee passed spent bill. Boehner announced that he would vote for bill despite political opposition. The bill passes the House Appropriations committee with a 7-4 vote. Both chamber approved bill with no objection from Republicans.\n",
      "\n",
      "Output: \n",
      "House Budget Committee passed a spending bill. House Budget Committee also passed a speech by House speaker Paul Ryan. House Speaker Boehner also spoke at the hearing. House budget bill goes to the Senate where it will likely go for a vote. The spending bill for this year is expected to pass.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = 'The House Budget Committee passed a spending bill.'\n",
    "\n",
    "encoded_input_ids_1 = tokenizer(sentence, return_tensors=\"pt\", add_special_tokens=False).input_ids.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    generation_output = model.generate(\n",
    "        input_ids = encoded_input_ids_1,\n",
    "        num_return_sequences=5, \n",
    "        generation_config = generation_config,\n",
    "        return_dict_in_generate = True,\n",
    "        output_scores = True\n",
    "    )\n",
    "\n",
    "for s in generation_output.sequences:\n",
    "    print(\"Output: \")\n",
    "    output = tokenizer.decode(s, skip_special_tokens=True)\n",
    "    print(output)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a6c3e4-7906-4f55-ae6b-11fa4b7461e2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Beam Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1217aadb-5d7f-4913-8796-8a564b0bb1a7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sentence = 'The House Budget Committee passed a spending bill.'\n",
    "\n",
    "generation_config = model.generation_config\n",
    "generation_config.do_sample = False\n",
    "generation_config.num_beams = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4271cf81-5c61-4914-931d-4f8de6ff441a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Beam size of  1\n",
      "House Budget Committee passed a spending bill. House Budget Committee passing a spendingBill. House budget Committee passed spending bill, passed bill. Bill passed by House Budget committee. House passed spending Bill. House passes spending bill; bill passed by Senate. House votes on bill. Senate votes on spending bill and passes bill.\n",
      "\n",
      "## Beam size of  2\n",
      "House Budget Committee passed a spending bill. House Budget Committee passing a bill to fund the government. House budget committee passed a bill that would fund the U.S. government through 2018. House passed a budget bill that will fund the country's government through 2019. The bill was passed by the House of Representatives and the Senate.\n",
      "\n",
      "## Beam size of  3\n",
      "House Budget Committee passes a spending bill. House Budget Committee passed a spending bills. House budget committee passed a bill to fund the government. The bill was passed by the House of Representatives. The Senate will vote on the bill later this month. The spending bill is expected to be passed within the week.\n",
      "\n",
      "## Beam size of  4\n",
      "House Budget Committee passes a spending bill. House Budget Committee passed a spending bills. House budget committee passed a bill to fund the government. The spending bill was passed by the House of Representatives. The Senate will vote on the spending bill later this month. The bill is expected to be approved by the Senate on Thursday.\n",
      "\n",
      "## Beam size of  5\n",
      "House Budget Committee passes a spending bill. House Budget Committee passed a spending bills. House budget committee passed a bill to fund the government. The bill was passed by the House of Representatives. The Senate will vote on the bill later this month. The spending bill is expected to pass in the next few days.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in range(1,6):\n",
    "\n",
    "    print(\"## Beam size of \", n)\n",
    "    generation_config.num_beams = n\n",
    "    decode_and_print(model, generation_config, sentence)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcae9c9-6f66-45f4-bb49-cac61ddd7b12",
   "metadata": {},
   "source": [
    "# Decoding with Constraints\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69d88892-d8a0-4d62-88aa-77e5f61a1e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cuda.is_available: \t True\n",
      "cuda.device_count: \t 1\n",
      "cuda.current_device: \t 0\n",
      "cuda.device: \t\t <torch.cuda.device object at 0x7f5c4f47be20>\n",
      "\n",
      "cuda.get_device_name: \t NVIDIA GeForce RTX 3050 Ti Laptop GPU\n",
      "total memory: \t\t 4294508544\n",
      "reserved memory:\t 0\n",
      "allocated memory:\t 0\n",
      "\n",
      "device name: \t\t cuda:0\n",
      "transformers: \t\t 4.29.2\n",
      "pytorch: \t\t 2.0.0\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import transformers\n",
    "import torch \n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "def cuda_info():\n",
    "    print()\n",
    "    print(\"cuda.is_available: \\t\", torch.cuda.is_available())\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"cuda.device_count: \\t\", torch.cuda.device_count())\n",
    "        print(\"cuda.current_device: \\t\", torch.cuda.current_device())\n",
    "        print(\"cuda.device: \\t\\t\", torch.cuda.device(torch.cuda.current_device()))\n",
    "        print()\n",
    "        print(\"cuda.get_device_name: \\t\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "        print(\"total memory: \\t\\t\", torch.cuda.get_device_properties(0).total_memory)\n",
    "        print(\"reserved memory:\\t\", torch.cuda.memory_reserved(0))\n",
    "        print(\"allocated memory:\\t\", torch.cuda.memory_allocated(0))\n",
    "\n",
    "\n",
    "    device = \"cuda:\" + str(torch.cuda.current_device()) if torch.cuda.is_available() else \"cpu\"\n",
    "    print()\n",
    "    print(\"device name: \\t\\t\", device)\n",
    "    print(\"transformers: \\t\\t\", transformers.__version__)\n",
    "    print(\"pytorch: \\t\\t\", torch.__version__)\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\n",
    "\n",
    "cuda_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b611331-7827-4639-a5a4-ea933cbc1a82",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Repetitions and word lists\n",
    "### n-gram Repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c17e212c-4890-4414-af02-5d212a6cad09",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "/home/jmag/.conda/envs/tutorials/lib/python3.9/site-packages/transformers/generation/utils.py:1346: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: \n",
      "The House Budget Committee passed a spending bill on Thursday that would cut the deficit by $1.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = 'The House Budget Committee passed a spending bill'\n",
    "\n",
    "encoded_input_ids_1 = tokenizer(sentence, return_tensors=\"pt\", add_special_tokens=False).input_ids.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    generation_output = model.generate(\n",
    "        input_ids = encoded_input_ids_1,\n",
    "        no_repeat_ngram_size=1,\n",
    "        return_dict_in_generate = True,\n",
    "        output_scores = True\n",
    "    )\n",
    "\n",
    "for s in generation_output.sequences:\n",
    "    print(\"Output: \")\n",
    "    output = tokenizer.decode(s, skip_special_tokens=True)\n",
    "    print(output)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcee34b2-7507-4651-8417-b4de73dd4243",
   "metadata": {},
   "source": [
    "### Force words and bad words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4e84aee2-504c-434c-9218-d74bc603dc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Force word ids:\n",
      "  DisjunctiveConstraint:  [[820, 734], [820, 530]]\n",
      "  PhrasalConstraint:  [47408, 783, 393, 4656]\n"
     ]
    }
   ],
   "source": [
    "sentence = 'The soldiers'\n",
    "input_ids = tokenizer(sentence, return_tensors=\"pt\", add_special_tokens=False).input_ids.to(device)\n",
    "\n",
    "## Forced words\n",
    "force_disjunctive = [\"day two\", \"day one\"]\n",
    "force_phrasal = \"leave now or die\"\n",
    "\n",
    "force_words_ids = [ tokenizer(force_disjunctive, add_special_tokens=False).input_ids,\n",
    "                    tokenizer(force_phrasal, add_special_tokens=False).input_ids\n",
    "                  ]\n",
    "\n",
    "print(\"## Force word ids:\")\n",
    "for word_ids in force_words_ids:\n",
    "    if isinstance(word_ids[0], list):\n",
    "        print(\"  DisjunctiveConstraint: \", word_ids)\n",
    "    else:\n",
    "        print(\"  PhrasalConstraint: \", word_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2e294ceb-129f-40de-9096-23fa7eb93dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Bad word ids:\n",
      "PhrasalConstraint:  [1929, 296]\n",
      "PhrasalConstraint:  [1941]\n"
     ]
    }
   ],
   "source": [
    "## Bad words\n",
    "bad_words_set = [\"whom\", \"year\"]\n",
    "bad_words_ids = tokenizer(bad_words_set, add_special_tokens=False).input_ids\n",
    "\n",
    "print(\"## Bad word ids:\")\n",
    "for word_ids in bad_words_ids:\n",
    "    if isinstance(word_ids[0], list):\n",
    "        print(\"DisjunctiveConstraint: \", word_ids)\n",
    "    else:\n",
    "        print(\"PhrasalConstraint: \", word_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8db62e-f342-468d-b4c9-db59429b263d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "generation_output = model.generate(\n",
    "    input_ids = input_ids,\n",
    "    force_words_ids=force_words_ids,\n",
    "    bad_words_ids=bad_words_ids,\n",
    "    num_beams = 10,\n",
    "    num_return_sequences=1,\n",
    "    no_repeat_ngram_size=6,\n",
    "    remove_invalid_values=True,\n",
    "    output_scores = True\n",
    ")\n",
    "\n",
    "for s in generation_output:\n",
    "    print(\"## Output: \")\n",
    "    output = tokenizer.decode(s, skip_special_tokens=True)\n",
    "    print(output)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c3f06a-aaa2-46b0-af95-fc7031f449f4",
   "metadata": {},
   "source": [
    "## Constraints\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ef104a-de7d-433c-ac89-967ea5e8363a",
   "metadata": {},
   "source": [
    "### Phrasal Constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bf0771b-150c-4264-8d7e-ed5394d6aef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The soldiers, who had been stationed at the base, had been ordered to leave the area.\n",
      "\n",
      "The soldiers, who were stationedat the base\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, PhrasalConstraint\n",
    "\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\n",
    "#model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\").to(device)\n",
    "\n",
    "encoder_input_str = \"The soldiers\"\n",
    "input_ids = tokenizer(encoder_input_str, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "\n",
    "force_flexible_set = 'at the base'\n",
    "tk_list = tokenizer(force_flexible_set, add_special_tokens=False).input_ids\n",
    "\n",
    "constraints = [\n",
    "    PhrasalConstraint(tk_list)\n",
    "]\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    constraints=constraints,\n",
    "    num_beams=10,\n",
    "    num_return_sequences=1,\n",
    "    no_repeat_ngram_size=5,\n",
    "    max_length = 30,\n",
    "    remove_invalid_values=True\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e58b87d-0458-498a-a6fa-b7e9bc31e236",
   "metadata": {},
   "source": [
    "### Disjunctive Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6efa114c-a471-41e6-a7ff-0d36c49691a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25967], [3847]]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, PhrasalConstraint, DisjunctiveConstraint\n",
    "\n",
    "encoder_input_str = \"The soldiers\"\n",
    "input_ids = tokenizer(encoder_input_str, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "force_words_set1 = [\" stationed\", \"night\"]\n",
    "words_ids_set1 = tokenizer(force_words_set1, add_special_tokens=False).input_ids\n",
    "print(words_ids_set1)\n",
    "\n",
    "constraints = [\n",
    "    DisjunctiveConstraint(words_ids_set1)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34642d97-d9a4-4a8e-8efc-6a443e5d0a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ä stationed'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(25967)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8da56ae7-5133-4c17-8c06-c5223b6304d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The soldiers, who had been stationed at the base, were taken to a nearby hospital, where they were treated for minor injuries and released.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    constraints=constraints,\n",
    "    num_beams=10,\n",
    "    num_return_sequences=1,\n",
    "    max_length = 30,\n",
    "    no_repeat_ngram_size=6,\n",
    "    remove_invalid_values=True\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f52bc5-0784-485c-a2f0-5715cecd59a3",
   "metadata": {},
   "source": [
    "### List of Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7df2be57-0be2-43ce-b6f0-d94e677c1fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[' stationed', 'in the field']\n",
      "{25967: {}, 259: {262: {2214: {}}}}\n",
      "\n",
      "[' hospital']\n",
      "{4436: {}}\n",
      "\n",
      " at the battle\n",
      "[379, 262, 3344]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, PhrasalConstraint, DisjunctiveConstraint\n",
    "\n",
    "# The prompt\n",
    "encoder_input_str = \"The soldiers\"\n",
    "input_ids = tokenizer(encoder_input_str, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "# First constraint\n",
    "force_words_set1 = [\" stationed\", \"in the field\"]\n",
    "words_ids_set1 = tokenizer(force_words_set1, add_special_tokens=False).input_ids\n",
    "constraint_1 = DisjunctiveConstraint(words_ids_set1)\n",
    "\n",
    "print()\n",
    "print(force_words_set1)\n",
    "print(constraint_1.trie.trie)\n",
    "\n",
    "# Second constraint\n",
    "force_words_set2 = [\" hospital\"]\n",
    "words_ids_set2 = tokenizer(force_words_set2, add_special_tokens=False).input_ids\n",
    "constraint_2 = DisjunctiveConstraint(words_ids_set2)\n",
    "\n",
    "print()\n",
    "print(force_words_set2)\n",
    "print(constraint_2.trie.trie)\n",
    "\n",
    "# Third constraint\n",
    "force_flexible_set = \" at the battle\"\n",
    "phrasal_constraints = tokenizer(force_flexible_set, add_special_tokens=False).input_ids\n",
    "constraint_3 = PhrasalConstraint(phrasal_constraints)\n",
    "\n",
    "print()\n",
    "print(force_flexible_set)\n",
    "print(constraint_3.token_ids)\n",
    "\n",
    "# The list of constraints\n",
    "constraints = [ constraint_1, constraint_2,constraint_3 ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b7ebd77b-cea5-40b9-b112-db8e79853389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The soldiers stationed at the base were not allowed to leave the base until the end of the war.\n",
      "\n",
      "\"We were told at the battle hospital\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    constraints=constraints,\n",
    "    num_beams=10,\n",
    "    num_return_sequences=1,\n",
    "    max_length = 30,\n",
    "    no_repeat_ngram_size=5,\n",
    "    remove_invalid_values=True\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5162ab5c-b756-402f-b625-8d578db3065a",
   "metadata": {},
   "source": [
    "## Low-level API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "979a7ff1-dc5e-4f8d-bcbc-1a0766d268b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The soldier, who was wearing a black T-shirt and jeans, said he had been in the country for two years.\\n\\n\"I was in the country for two years. I was in the country for two years,\" he said.black']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    ConstrainedBeamSearchScorer,\n",
    "    PhrasalConstraint, MaxLengthCriteria,\n",
    "    LogitsProcessorList, StoppingCriteriaList,\n",
    "    MinLengthLogitsProcessor\n",
    ")\n",
    "\n",
    "# lets run beam search using 3 beams\n",
    "num_beams = 3\n",
    "\n",
    "encoder_input_str = \"The soldier\"\n",
    "input_ids = tokenizer(encoder_input_str, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "input_ids = input_ids.repeat_interleave(num_beams, dim=0)\n",
    "\n",
    "constraint_str = [\"black\", \"country\"]\n",
    "constraint_token_ids = tokenizer.encode(constraint_str)[:-1]  # slice to remove eos token\n",
    "constraints = [PhrasalConstraint(token_ids=constraint_token_ids)]\n",
    "\n",
    "# instantiate beam scorer\n",
    "beam_scorer = ConstrainedBeamSearchScorer(\n",
    "    batch_size=1, num_beams=num_beams, device=model.device, max_length = 50, constraints=constraints\n",
    ")\n",
    "\n",
    "# instantiate logits processors\n",
    "logits_processor = LogitsProcessorList(\n",
    "    [\n",
    "        MinLengthLogitsProcessor(5, eos_token_id=model.config.eos_token_id),\n",
    "    ]\n",
    ")\n",
    "\n",
    "outputs = model.constrained_beam_search(\n",
    "    input_ids, beam_scorer, constraints=constraints, stopping_criteria=StoppingCriteriaList([MaxLengthCriteria(max_length=50)]), logits_processor=logits_processor\n",
    ")\n",
    "\n",
    "tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206b77ad-f7a8-4b76-b1d5-cf20d1b031cb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tutorials (GPU)",
   "language": "python",
   "name": "tutorials"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alexa TaskBot Dialog State Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Intent detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import transformers\n",
    "import json\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "\n",
    "model_finetuned = './twiz-intent-model'\n",
    "with open(os.path.join(model_finetuned + '/all_intents.json'), 'r') as all_intents_json:\n",
    "    all_intents = json.load(all_intents_json) # contains the written out names of intents. also implicitly\n",
    "\n",
    "tokenizer_name = 'roberta-base' # try 'bert-base-uncased', 'bert-base-cased', 'bert-large-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name) # loads a tokenizer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_finetuned, \n",
    "                                                           num_labels=len(all_intents)) # Loads the BERT model weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GetCuriositiesIntent',\n",
       " 'GreetingIntent',\n",
       " 'AMAZON.SelectIntent',\n",
       " 'ShowStepsIntent',\n",
       " 'IdentifyRestrictionsIntent',\n",
       " 'ProvideUserNameIntent',\n",
       " 'MoreOptionsIntent',\n",
       " 'AMAZON.RepeatIntent',\n",
       " 'AMAZON.HelpIntent',\n",
       " 'QuestionIntent',\n",
       " 'MoreDetailIntent',\n",
       " 'AdjustServingsIntent',\n",
       " 'GoToStepIntent',\n",
       " 'SetTimerIntent',\n",
       " 'OutOfScopeIntent',\n",
       " 'AMAZON.FallbackIntent',\n",
       " 'PreviousStepIntent',\n",
       " 'TerminateCurrentTaskIntent',\n",
       " 'ChitChatIntent',\n",
       " 'CompleteTaskIntent',\n",
       " 'NoneOfTheseIntent',\n",
       " 'ShoppingIntent',\n",
       " 'AMAZON.PauseIntent',\n",
       " 'AMAZON.CancelIntent',\n",
       " 'StartStepsIntent',\n",
       " 'InappropriateIntent',\n",
       " 'AMAZON.NoIntent',\n",
       " 'SuggestionsIntent',\n",
       " 'ResumeTaskIntent',\n",
       " 'IngredientsConfirmationIntent',\n",
       " 'NextStepIntent',\n",
       " 'IdentifyProcessIntent',\n",
       " 'NoRestrictionsIntent',\n",
       " 'AMAZON.YesIntent',\n",
       " 'SubstitutionIntent',\n",
       " 'AMAZON.StopIntent']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IdentifyProcessIntent'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_u = \"I can help you finding delicious recipes. What kind of recipe would you like to search for?\"\n",
    "user_u = \"Can you find me a chicken recipe?\"\n",
    "\n",
    "input_encoding = tokenizer.encode_plus(agent_u, user_u, return_tensors='pt', padding='max_length', truncation=True, max_length=512)\n",
    "outputs = model(**input_encoding)\n",
    "\n",
    "logits = outputs.logits\n",
    "idx = logits.argmax(-1).item()\n",
    "all_intents[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SuggestionsIntent'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_u = \"I can help you finding delicious recipes. What kind of recipe would you like to search for?\"\n",
    "user_u = \"Show me the suggestions\"\n",
    "\n",
    "input_encoding = tokenizer.encode_plus(agent_u, user_u, return_tensors='pt', padding='max_length', truncation=True, max_length=512)\n",
    "outputs = model(**input_encoding)\n",
    "\n",
    "logits = outputs.logits\n",
    "idx = logits.argmax(-1).item()\n",
    "all_intents[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AMAZON.SelectIntent'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_u = \"I can help you finding delicious recipes. What kind of recipe would you like to search for?\"\n",
    "user_u = \"Show me the second recipe.\"\n",
    "\n",
    "input_encoding = tokenizer.encode_plus(agent_u, user_u, return_tensors='pt', padding='max_length', truncation=True, max_length=512)\n",
    "outputs = model(**input_encoding)\n",
    "\n",
    "logits = outputs.logits\n",
    "idx = logits.argmax(-1).item()\n",
    "all_intents[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IdentifyProcessIntent'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_u = \"I can help you finding delicious recipes. What kind of recipe would you like to search for?\"\n",
    "user_u = \"Find me fish recipes.\"\n",
    "\n",
    "input_encoding = tokenizer.encode_plus(agent_u, user_u, return_tensors='pt', padding='max_length', truncation=True, max_length=512)\n",
    "outputs = model(**input_encoding)\n",
    "\n",
    "logits = outputs.logits\n",
    "idx = logits.argmax(-1).item()\n",
    "all_intents[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IngredientsConfirmationIntent'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_u = \"Here is some information about Bacon and Tomato Pasta. It has a 4.8 star rating.  It is estimated to take about 35 minutes. It serves 4. Its difficulty level is Easy.  If this is not quite what you are looking for say, go back. Otherwise I can show you the ingredients or we can start the cooking.\"\n",
    "user_u = \"What are the recipe ingredients?\"\n",
    "\n",
    "input_encoding = tokenizer.encode_plus(agent_u, user_u, return_tensors='pt', padding='max_length', truncation=True, max_length=512)\n",
    "outputs = model(**input_encoding)\n",
    "\n",
    "logits = outputs.logits\n",
    "idx = logits.argmax(-1).item()\n",
    "all_intents[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'StartStepsIntent'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_u = \"Here is some information about Bacon and Tomato Pasta. It has a 4.8 star rating.  It is estimated to take about 35 minutes. It serves 4. Its difficulty level is Easy.  If this is not quite what you are looking for say, go back. Otherwise I can show you the ingredients or we can start the cooking.\"\n",
    "user_u = \"This looks great. Let's start the recipe.\"\n",
    "\n",
    "input_encoding = tokenizer.encode_plus(agent_u, user_u, return_tensors='pt', padding='max_length', truncation=True, max_length=512)\n",
    "outputs = model(**input_encoding)\n",
    "\n",
    "logits = outputs.logits\n",
    "idx = logits.argmax(-1).item()\n",
    "all_intents[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NextStepIntent'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_u = \"Let me know when you're ready to move on the next step.\"\n",
    "user_u = \"Go on\"\n",
    "\n",
    "input_encoding = tokenizer.encode_plus(agent_u, user_u, return_tensors='pt', padding='max_length', truncation=True, max_length=512)\n",
    "outputs = model(**input_encoding)\n",
    "\n",
    "logits = outputs.logits\n",
    "idx = logits.argmax(-1).item()\n",
    "all_intents[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PreviousStepIntent'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_u = \"Let me know when you're ready to move on the next step.\"\n",
    "user_u = \"go back.\"\n",
    "\n",
    "input_encoding = tokenizer.encode_plus(agent_u, user_u, return_tensors='pt', padding='max_length', truncation=True, max_length=512)\n",
    "outputs = model(**input_encoding)\n",
    "\n",
    "logits = outputs.logits\n",
    "idx = logits.argmax(-1).item()\n",
    "all_intents[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-Shot Slot Filling as QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d394e9542e6e4c93ade3c55370c0f193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad01f16cd59141b5880badf9905e0bd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/496M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0b911e8742d4dc0b7cd66c9ee4f0b73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/79.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82099abaa77b49b691c18a367ea5db81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6d84aa13be84dda96af2b8e46857a7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "906e92b17c04480cbf597e4c4e91ef08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
    "import torch as torch\n",
    "\n",
    "model_name = \"deepset/roberta-base-squad2\"\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"I'd like a salad with tomatos, lettuce and strawberries.\"\n",
    "question = \"What are the ingredients?\"\n",
    "\n",
    "input_encoding = tokenizer.encode_plus(prompt, user_u, return_tensors='pt', padding='max_length', truncation=True, max_length=512)\n",
    "outputs = model(**input_encoding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(17)\n",
      "tensor(23)\n"
     ]
    }
   ],
   "source": [
    "# Get the most likely beginning of answer with the argmax of the score\n",
    "answer_start_scores = outputs.start_logits\n",
    "answer_start = torch.argmax(answer_start_scores)\n",
    "\n",
    "# Get the most likely end of answer with the argmax of the score\n",
    "answer_end_scores = outputs.end_logits\n",
    "answer_end = torch.argmax(answer_end_scores) + 1\n",
    "\n",
    "print(answer_start)\n",
    "print(answer_end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tomatos, lettuce and strawberries\n"
     ]
    }
   ],
   "source": [
    "answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_encoding.input_ids[0][answer_start:answer_end]))\n",
    "\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.3748808801174164, 'start': 30, 'end': 63, 'answer': 'tomatos, lettuce and strawberries'}\n"
     ]
    }
   ],
   "source": [
    "qa_pipeline = pipeline('question-answering', model=model, tokenizer=tokenizer)\n",
    "\n",
    "qa_input = {\n",
    "  'context': 'Yes. No. I''d like a salad with tomatos, lettuce and strawberries.',\n",
    "  'question': 'What are the ingredients?'\n",
    "}\n",
    "\n",
    "answer = qa_pipeline(qa_input)\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal Conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json as json\n",
    "\n",
    "with open(\"recipes_data.json\", \"r\") as read_file:\n",
    "    data = json.load(read_file)\n",
    "\n",
    "imgA = data['0']['images'][0]['url']\n",
    "titleA = data['0']['displayName']\n",
    "propA = \"Serves \" + str(data['0']['servings'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video, Image, HTML, display\n",
    "\n",
    "def displayResults(titleA, imgA, propA, titleB, imgB, propB, titleC, imgC, propC):\n",
    "    display(HTML(f\"\"\"\n",
    "    <div class =\"row\" style=\"margin-left:100px\">\n",
    "       <div class=\"col-xs-6\">\n",
    "        <div class =\"images\" style=\"display:inline-block;\">\n",
    "            <img src=\"{imgA}\" class=\"img-responsive\" width=\"80px\">\n",
    "        </div>\n",
    "        <div class =\"images\" style=\"display:inline-block;\">\n",
    "                      {titleA} <br>\n",
    "                      {propA} <br>\n",
    "        </div>\n",
    "        <div class =\"images\" style=\"display:inline-block;\">\n",
    "            <img src=\"{imgB}\" class=\"img-responsive\" width=\"80\">\n",
    "        </div>\n",
    "        <div class =\"images\" style=\"display:inline-block;\">\n",
    "                      {titleB} <br>\n",
    "                      {propB} <br>\n",
    "        </div>\n",
    "        <div class =\"images\" style=\"display:inline-block;\">\n",
    "            <img src=\"{imgC}\" class=\"img-responsive\" width=\"80\">\n",
    "        </div>\n",
    "                      {titleC} <br>\n",
    "                      {propC} <br>\n",
    "        </div>\n",
    "       </div>\n",
    "    </div>\n",
    "    \"\"\"))\n",
    "\n",
    "def displayStep(text, img):\n",
    "    display(HTML(f\"\"\"\n",
    "    <div class =\"row\" style=\"margin-left:100px\">\n",
    "        <img src=\"{img}\" class=\"img-responsive\" width=\"80px\">\n",
    "        {text}<br>\n",
    "    </div>\n",
    "        \"\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " BOT: Hello, I am a TaskBot and I can help you with cooking tasks. Which recipe would you like to do?\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "USER: Chicken recipes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " BOT: Great! These are the results I found:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class =\"row\" style=\"margin-left:100px\">\n",
       "       <div class=\"col-xs-6\">\n",
       "        <div class =\"images\" style=\"display:inline-block;\">\n",
       "            <img src=\"https://m.media-amazon.com/images/S/alexa-kitchen-msa-na-prod/recipes/thekitchn/016aa4923f044e1bad4cb2802f04133f7cf787b9bbf4fceb52438ecb70b28d89.jpg\" class=\"img-responsive\" width=\"80px\">\n",
       "        </div>\n",
       "        <div class =\"images\" style=\"display:inline-block;\">\n",
       "                      How To Make Chicken Parmesan <br>\n",
       "                      Serves 4 <br>\n",
       "        </div>\n",
       "        <div class =\"images\" style=\"display:inline-block;\">\n",
       "            <img src=\"https://m.media-amazon.com/images/S/alexa-kitchen-msa-na-prod/recipes/thekitchn/016aa4923f044e1bad4cb2802f04133f7cf787b9bbf4fceb52438ecb70b28d89.jpg\" class=\"img-responsive\" width=\"80\">\n",
       "        </div>\n",
       "        <div class =\"images\" style=\"display:inline-block;\">\n",
       "                      How To Make Chicken Parmesan <br>\n",
       "                      Serves 4 <br>\n",
       "        </div>\n",
       "        <div class =\"images\" style=\"display:inline-block;\">\n",
       "            <img src=\"https://m.media-amazon.com/images/S/alexa-kitchen-msa-na-prod/recipes/thekitchn/016aa4923f044e1bad4cb2802f04133f7cf787b9bbf4fceb52438ecb70b28d89.jpg\" class=\"img-responsive\" width=\"80\">\n",
       "        </div>\n",
       "                      How To Make Chicken Parmesan <br>\n",
       "                      Serves 4 <br>\n",
       "        </div>\n",
       "       </div>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Which recipe would you like to do? Or, would you like to search for something different?\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "USER: I love these ones lets start the first\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " BOT: That looks delicious! Let's start!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class =\"row\" style=\"margin-left:100px\">\n",
       "        <img src=\"https://m.media-amazon.com/images/S/alexa-kitchen-msa-na-prod/recipes/thekitchn/016aa4923f044e1bad4cb2802f04133f7cf787b9bbf4fceb52438ecb70b28d89.jpg\" class=\"img-responsive\" width=\"80px\">\n",
       "        Heat the oven and prepare for frying: Arrange a rack in the middle of the oven and heat to 375°F. Add enough oil to a wide, deep saucepan or pot so that it is 3/4-inch deep. If you have a deep-fry or candy thermometer, place it near the stove or attach it to the pan. Line a large platter with a few sheets of paper towels and set near the stove.<br>\n",
       "    </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " BOT: Say next when you're done.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "USER: next\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class =\"row\" style=\"margin-left:100px\">\n",
       "        <img src=\"https://m.media-amazon.com/images/S/alexa-kitchen-msa-na-prod/recipes/thekitchn/016aa4923f044e1bad4cb2802f04133f7cf787b9bbf4fceb52438ecb70b28d89.jpg\" class=\"img-responsive\" width=\"80px\">\n",
       "        Set up a breading station: Line up 3 shallow bowls or 8-inch square rimmed dishes side by side. Place the flour, 1 teaspoon of the salt, and 1/2 teaspoon of the black pepper in the first dish and mix to combine. Place the eggs, water, and remaining 1 teaspoon of the salt to the second dish and beat lightly with a fork to combine. Pour the breadcrumbs into the third dish.<br>\n",
       "    </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " BOT: Say next when you're done.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "USER: next\n"
     ]
    }
   ],
   "source": [
    "# Turn 1\n",
    "print(\" BOT: Hello, I am a TaskBot and I can help you with cooking tasks. Which recipe would you like to do?\")\n",
    "print()\n",
    "val = input(\"USER:\")\n",
    "\n",
    "# Turn 2\n",
    "print()\n",
    "print(\" BOT: Great! These are the results I found:\")\n",
    "print()\n",
    "displayResults(titleA, imgA, propA, titleA, imgA, propA, titleA, imgA, propA)    \n",
    "print(\"      Which recipe would you like to do? Or, would you like to search for something different?\")\n",
    "print()\n",
    "val = input(\"USER:\")\n",
    "\n",
    "# Turn 3\n",
    "print()\n",
    "print(\" BOT: That looks delicious! Let's start!\")\n",
    "print()\n",
    "displayStep(data['0']['instructions'][0]['stepText'], imgA)    \n",
    "\n",
    "# Turn 4\n",
    "print(\" BOT: Say next when you're done.\")\n",
    "print()\n",
    "val = input(\"USER:\")\n",
    "print()\n",
    "displayStep(data['0']['instructions'][1]['stepText'], imgA)    \n",
    "\n",
    "# Turn 5\n",
    "print(\" BOT: Say next when you're done.\")\n",
    "print()\n",
    "val = input(\"USER:\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "model_view_bert_msmarco_aula.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Tutorials (GPU)",
   "language": "python",
   "name": "tutorials"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

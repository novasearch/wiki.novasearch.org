{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Week 1: ActivityNet Video Data Preparation and Indexing\n",
    "\n",
    "In this example we will use the ActivityNet dataset https://github.com/activitynet/ActivityNet. \n",
    "\n",
    " - Select the 10 videos with more moments.\n",
    " - Download these videos onto your computer.\n",
    " - Extract the frames for every video.\n",
    " - Read the textual descriptions of each video.\n",
    " - Index the video data in OpenSearch.\n",
    "\n",
    " In this week, you will index the video data and make it searchable with OpenSearch. You should refer to the OpenSearch tutorial laboratory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select videos\n",
    "Download the `activity_net.v1-3.min.json` file containing the list of videos. The file is in the github repository of ActivityNet.\n",
    "Parse this file and select the 10 videos with more moments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "with open('activity_net.v1-3.min.json', 'r') as json_data:\n",
    "    data = json.load(json_data)\n",
    "\n",
    "# Complete here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video frame extraction\n",
    "\n",
    "PyAV is a wrapper library providing you access to `ffmpeg`, a command-line video processing tool. In the example below, you will be able to extract frames from the a video shot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<av.VideoFrame, pts=0 yuv420p 1280x720 at 0x7fe5544f1ea0>\n",
      "<av.VideoFrame, pts=75 yuv420p 1280x720 at 0x7fe52a097100>\n",
      "<av.VideoFrame, pts=150 yuv420p 1280x720 at 0x7fe52d401660>\n"
     ]
    }
   ],
   "source": [
    "import av\n",
    "import av.datasets\n",
    "\n",
    "content = av.datasets.curated(\"pexels/time-lapse-video-of-night-sky-857195.mp4\")\n",
    "with av.open(content) as container:\n",
    "    # Signal that we only want to look at keyframes.\n",
    "    stream = container.streams.video[0]\n",
    "    stream.codec_context.skip_frame = \"NONKEY\"\n",
    "\n",
    "    for i, frame in enumerate(container.decode(stream)):\n",
    "        print(frame)\n",
    "        frame.to_image().save(f\"night-sky.{i:04d}.jpg\", quality=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video metadata\n",
    "\n",
    "Process the video metadata provided in the `json` file and index the video data in OpenSearch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video captions\n",
    "\n",
    "The ActivityNetCaptions dataset https://cs.stanford.edu/people/ranjaykrishna/densevid/ dataset provides a textual description of each videos. Index the video captions on a text field of your OpenSearch index."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-cv-ir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

WORK IN PROGRESS: Some guidelines/tutorials for software installation in the Rocks Cluster.

== Python Stuff ==

=== General Advice ===

Compute nodes have a set of useful libraries installed like numpy, scipy, pandas, etc...
The pip tool, which allows one to easily install new libraries and is also available. It may be used to install any python library from the Python Package Index or from a git repository.
Example of a command to install a package/library:

<code>pip install <package_name></code>
 
Since we are simple peasants on the cluster and we don't have sudo (it makes a lot of sense :)) we need to install libraries locally.
To achieve this, one option is to add the option <code>--user</code> to the pip install command:

<code>pip install <package_name> --user</code>

For more info see: [http://pip-python3.readthedocs.org/en/latest/user_guide.html#user-installs]

To upgrade a library we specify the argument <code>--upgrade</code>, like this:

<code>pip install --upgrade <package_name> --user</code>

=== Machine Learning General Packages ===


==== Scipy ====

The Scipy package[https://www.scipy.org/] provides a collection of mathematics, science, and engineering related libraries. It includes packages like numpy, matplotlib,pandas, ipython, among others. 

As any other package, Scipy can be installed by issuing the command:

<code>pip install --upgrade scipy --user</code>

However, it is likely that it will fail due to the fact that python isn't able to find a BLAS library. Since our cluster Rocks, we have MKL from Intel! To use it, we need to load it and tell pip which MKL version we wan't numpy to use.

To load mkl on the cluster:

<code>module load mkl</code> (confirm if lapack is needed!)



* Create a configuration file for numpy named <code>.numpy-site.cfg</code> in the $HOME folder:

:: <code>touch /home/dsemedo/.numpy-site.cfg</code>
* Copy the contents of a sample numpy config file available at [https://github.com/numpy/numpy/blob/master/site.cfg.example] to the created file.

Change the MKL section to:
 
 # MKL
 # ----
 # MKL is Intel's very optimized yet proprietary implementation of BLAS and
 # Lapack.
 # For recent (9.0.21, for example) mkl, you need to change the names of the
 # lapack library. Assuming you installed the mkl in /opt, for a 32 bits cpu:
 [mkl]
 library_dirs = /opt/intel/composer_xe_2013_sp1.2.144/mkl/lib/intel64 
 include_dirs = /opt/intel/composer_xe_2013_sp1.2.144/mkl/include
 mkl_libs = mkl_rt


After this, Scipy installs correctly and MKL is used in Numpy.



==== scikit-learn ====

<code>pip install --upgrade scikit-learn --user</code>

=== Deep Learning Packages ===

==== Theano ====

Theano is a Python library that allows the definition, optimization, and evaluation of mathematical expressions involving multi-dimensional arrays efficiently. 

Install the latest version of Theano using the git repository:

<code>pip install --upgrade https://github.com/Theano/Theano/archive/master.zip --user</code>

Theano supports CPU and GPU. To select which we want to use the Theano flags must be set:

* Setting the flags for each execution:
::<code>THEANO_FLAGS='floatX=float32,device=gpu0'  python <script>.py</code>

* Alternatively we can create a config file:
::<code>echo -e "[global]\nfloatX=float32\ndevice = gpu0\n" > ~/.theanorc</code>
:With this config, Theano will attempt to use the GPU for computations. If it fails to find a GPU, it will fallback to the CPU.


Additionally, we want Theano to also use MKL:

* Modify Theano config file by adding:
 [blas]
 ldflags = -L/opt/intel/composer_xe_2013_sp1.2.144/mkl/lib/intel64 -L/opt/intel/composer_xe_2013_sp1.2.144/compiler/lib/intel64 -lmkl_gf_lp64 -lmkl_intel_lp64 -lmkl_intel_thread -lmkl_gnu_thread -lmkl_core -lmkl_vml_avx -lmkl_def -ldl -lpthread -lm -lmkl_rt -liomp5

For more info about Theano flags see[http://deeplearning.net/software/theano/library/config.html].

==== Lasagne ====

Lasagne is a lightweight library to build and train neural networks in Theano.
It depends on Theano, therefore it must be installed first. To install Lasagne:

<code>pip install --upgrade https://github.com/Lasagne/Lasagne/archive/master.zip --user</code>

Lasagne documentation: [http://lasagne.readthedocs.org/en/latest/index.html]



==== Keras ====

"Keras is a minimalist, highly modular neural networks library, written in Python and capable of running on top of either TensorFlow or Theano. It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research."

Dependencies:

* cv2 -> <code>pip install cv2 --user</code>


<code>pip install git+git://github.com/Theano/Theano.git --user</code>


Keras Documentation: [http://keras.io/]

=== Computer Vision Packages ===

==== scikit-image ====

<code>pip install --upgrade scikit-image --user</code>








== OpenCV ==

Steps for installing OpenCV 3.1.0 with extra modules (OpenCV contrib). OpenCV will be compiled with support for OpenCL and CUDA.

Downloading OpenCV: [http://opencv.org/downloads.html]

Extra modules must be downloaded from git.

 $ git clone https://github.com/Itseez/opencv_contrib


From now on, let <opencv_contrib_dir> be the the downloaded opencv_contrib folder.

Load necessary modules:
 $ module load cmake gnutools mkl python eigen hdf5
Compiling OpenCV:
 $ cd <opencv_source>
 $ mkdir build && cd "$_"
 $ cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=<install_folder> -D INSTALL_C_EXAMPLES=OFF -D INSTALL_PYTHON_EXAMPLES=ON -D OPENCV_EXTRA_MODULES_PATH=<opencv_contrib_dir>/modules -D BUILD_EXAMPLES=ON -D ENABLE_FAST_MATH=1 -D CUDA_FAST_MATH=1 -D WITH_OPENCL=ON -D BUILD_opencv_python2=ON -D PYTHON_INCLUDE_DIR=/opt/python/include/python2.7 -D PYTHON_LIBRARY=/opt/python/lib/libpython2.7.so  ..
 $ make -j12
 $ make install

The final step is to add the path of cv2.so library to the PYTHONPATH variable, such that python finds it:
 # Add this line to ~/.bashrc
 export PYTHONPATH=$HOME/opencv_build/lib/python2.7/site-packages:$PYTHONPATH

To check if it installed correctly:
 $ python
 >>> import cv2

If the import succeeds then Python-OpenCV is installed.
 



==== Adding support for FFmpeg ====

Assuming that FFmpeg was compiled previously and the build directory is <ffmpeg_build>, the following environment variables must be set:

 export LD_LIBRARY_PATH=<ffmpeg_build>/lib/:$LD_LIBRARY_PATH
 export PKG_CONFIG_PATH=$PKG_CONFIG_PATH:<ffmpeg_build>/lib/pkgconfig
 export PKG_CONFIG_LIBDIR=$PKG_CONFIG_LIBDIR:<ffmpeg_build>/lib/

Now, cmake should be able to find FFmpeg.

NOTE: FFmpeg must be compiled with the following options: <code>./configure --enable-nonfree --enable-pic --enable-shared</code>

=== Common Problems ===

==== IPPICV hash mismatch ====

While creating the makefile for compilation, the lib ippicv will be automatically downloaded. However, the md5sum of the downloaded file will not match the hardcoded hash on the cmake.

Instead of changing cmake we can manually download the file. Download URL: [https://raw.githubusercontent.com/Itseez/opencv_3rdparty/81a676001ca8075ada498583e4166079e5744668/ippicv/ippicv_linux_20151201.tgz]
Steps:

 $ mkdir <opencv_source>/3rdparty/ippicv/downloads/linux-808b791a6eac9ed78d32a7666804320e && cd "$_"
 $ wget https://raw.githubusercontent.com/Itseez/opencv_3rdparty/81a676001ca8075ada498583e4166079e5744668/ippicv/ippicv_linux_20151201.tgz
 $ cd ../../ && mkdir unpack && cd "$_"
 $ cp ../downloads/linux-808b791a6eac9ed78d32a7666804320e/ippicv_linux_20151201.tgz .
 $ tar zxvf ippicv_linux_20151201.tgz

Alternatively, one can pass the option <code>-D WITH_IPP=OFF</code> to the cmake call to compile without the IPPICV lib.



== Caffe ==

Steps for installing the Caffe [http://caffe.berkeleyvision.org/installation.html]. Caffe is a deep learning framework made with expression, speed, and modularity in mind.

Caffe has the following dependencies:

* Cuda Toolkit and cuDNN (For GPU mode)
* OpenCV (optional but recommended)
* BLAS ( ATLAS, MKL, or OpenBLAS)
* Boost >= 1.55
* protobuf, glog, gflags, hdf5

With some luck, we only need to install glog and gflags, the remaining libraries are already installed

Load necessary modules:
 $ module load cmake gnutools mkl python eigen hdf5 boost mvapich2_eth

=== Installing missing dependencies ===

==== glog ====

Glog is available on git:

 $ git clone git@github.com:google/glog.git
 $ cd glog

The automake version on the cluster is different from the one that glog is expecting. To fix this:
 $ rm test-driver
 $ ln -s /opt/gnu/share/automake-1.15/test-driver test-driver

The configure has the aclocal tool version hardcoded aswell (version 1.14). In the rocks cluster the version 1.15 is available.
To fix this open the configure file and change the line:
 am__api_version='1.14'
to
 am__api_version='1.15'


Compiling glog:

 $ mkdir build && cd "$_"
 $ export CXXFLAGS="-fPIC" &&  cmake -DCMAKE_INSTALL_PREFIX=<install-folder> ..
 $ make VERBOSE=1
 $ make
 $ make install


==== gflags ====

Gflags is available on git:

 $ git clone git@github.com:gflags/gflags.git
 $ cd gflags


Compiling gflags:

 $ mkdir build && cd "$_"
 $ export CXXFLAGS="-fPIC" && cmake -DCMAKE_INSTALL_PREFIX=<install-folder> ..
 $ make
 $ make install

Make sure that the install-folder is on your PATH and LD_LIBRARY_PATH variables.


==== leveldb ====

Leveldb is available on git:

 $ git clone git@github.com:google/leveldb.git
 $ cd leveldb
 $ make
 $ cp --preserve=links libleveldb.* <install-folder>/lib
 $ cp -r include/leveldb <install-folder>/include/
 $ cp --preserve=links out-shared/libleveldb.so* ~/installed_libs/lib/


==== lmdb ====

Lmdb is available on git and through pip:

 $ pip install lmdb --user
 $ git clone https://github.com/LMDB/lmdb
 $ cd lmdb/libraries/liblmdb/

Open the Makefile and find the line <code>prefix  = /usr/local</code>. Change path to your install folder.

 $ make
 $ make install



=== Compiling ===

Caffe is available on git:

 $ git clone git@github.com:BVLC/caffe.git
 $ cd caffe
 $ cp Makefile.config.example Makefile.config

All the options for compiling Caffe are available in the file Makefile.config. We can make the following changes:

* Use cuDNN on the machine that has an NVIDIA card: Uncomment USE_CUDNN line.
* If we have OpenCV version >= 3: Uncomment OPENCV_VERSION := 3.
* Change CUDA dir to /opt/cuda (In a machine with NVIDIA card)
* Use MKL: set BLAS := mkl
* BLAS_INCLUDE := /opt/intel/composer_xe_2013_sp1.2.144/mkl/include
* BLAS_LIB := /opt/intel/composer_xe_2013_sp1.2.144/mkl/lib/intel64
* PYTHON_INCLUDE := /opt/python/include/python2.7 \
        /opt/python/lib/python2.7/site-packages/numpy/core/include/numpy/
* PYTHON_LIB := /opt/python/lib/
* Add include and lib  gflags and glogs folders to INCLUDE_DIRS and LIBRARY_DIRS.
* Add include and lib opencv folders to INCLUDE_DIRS and LIBRARY_DIRS.
* Add hdf5 path:
** Add /opt/hdf5/gnu/mvapich2_eth/include to INCLUDE_DIRS
** Add /opt/hdf5/gnu/mvapich2_eth/lib to LIBRARY_DIRS
* Add boost libraries path:
** Add /opt/hdf5/gnu/mvapich2_eth/include to INCLUDE_DIRS
** Add /opt/boost/gnu/mvapich2_eth/lib to LIBRARY_DIRS
* Add /usr/lib64 to LIBRARY_DIRS


The result should something like:

 INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include /home/dsemedo/installed_libs/include /home/dsemedo/opencv_build/include /opt/hdf5/gnu/mvapich2_eth/include /opt/boost/gnu/mvapich2_eth/include
 LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib /home/dsemedo/installed_libs/lib /home/dsemedo/opencv_build/lib /opt/hdf5/gnu/mvapich2_eth/lib /opt/boost/gnu/mvapich2_eth/lib /usr/lib64


Make was not finding the libsnappy.so so I did the following to solve the problem:
 ln -s /usr/lib64/libsnappy.so.1 ~/installed_libs/lib/libsnappy.so

Compile steps:

 $ mkdir build && cd "$_"
 $ cmake -DCMAKE_INSTALL_PREFIX=<install-folder> ..
 $ make
 $ make install